{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Source Code Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import git\n",
    "import re\n",
    "import tqdm\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "import sys\n",
    "import shutil\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_snippet(snippet, line_breaks=True):\n",
    "    token_re = re.compile(r'[a-z_]+')\n",
    "    line_comment_re = re.compile(r'[ \\t]*#.*')\n",
    "    block_comment_re = re.compile(r'(\\'\\'\\')|(\\\"\\\"\\\")')\n",
    "\n",
    "    output = ''\n",
    "\n",
    "    lines = snippet.split('\\n')\n",
    "    # boolean to track whether we are in a block comment\n",
    "    in_block_comment = False\n",
    "\n",
    "    for line in lines:\n",
    "\n",
    "        # check for block comment start/end\n",
    "        block_matches = block_comment_re.findall(line)\n",
    "\n",
    "        # if only one match, begin/end multiline comment\n",
    "        if len(block_matches) == 1:\n",
    "            in_block_comment = not in_block_comment  \n",
    "        \n",
    "        # if two matches, ignore the line\n",
    "        elif len(block_matches) == 2:\n",
    "            in_block_comment = False\n",
    "        \n",
    "        elif not in_block_comment:\n",
    "\n",
    "            # remove line/inline comments\n",
    "            no_comments = line_comment_re.sub('', line)\n",
    "\n",
    "            # get lowercase alphabetic characters\n",
    "            clean_line = ' '.join(token_re.findall(no_comments.lower()))\n",
    "\n",
    "            if line_breaks:\n",
    "                clean_line += '\\n'\n",
    "            else:\n",
    "                clean_line += ' '\n",
    "\n",
    "            # check for empty line\n",
    "            if clean_line != '\\n':\n",
    "                output += clean_line\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def has_flag self flagname import tempfile with tempfile namedtemporaryfile w suffix cpp as f f write int main int argc char argv return try self compile f name extra_postargs flagname except exception as exc if type exc __name__ compileerror raise return false return true \n",
      "def update_matplotlibrc path template_lines path read_text encoding utf splitlines true backend_line_idx idx for idx line in enumerate template_lines if template_lines backend_line_idx path write_text join template_lines encoding utf \n",
      "def finalize_options self cppflags os getenv cppflags if cppflags and coverage in cppflags self build_temp build self distribution ext_modules ext for package in good_packages for ext in package get_extensions super finalize_options \n",
      "def add_optimization_flags self env os environ copy if sys platform win return env enable_lto setupext config getboolean libs enable_lto fallback none  def prepare_flags name enable_lto if name in os environ if fno lto in os environ name if enable_lto is true raise valueerror configuration enable_lto true but contains fno lto format name enable_lto false return os environ name enable_lto return enable_lto _ enable_lto prepare_flags cflags enable_lto cppflags enable_lto prepare_flags cppflags enable_lto cxxflags enable_lto prepare_flags cxxflags enable_lto ldflags enable_lto prepare_flags ldflags enable_lto if enable_lto is false return env if has_flag self compiler fvisibility hidden for ext in self extensions ext extra_compile_args append fvisibility hidden cppflags append fvisibility hidden if has_flag self compiler fvisibility inlines hidden for ext in self extensions if self compiler detect_language ext sources cpp continue ext extra_compile_args append fvisibility inlines hidden cxxflags append fvisibility inlines hidden ranlib ranlib in env if not ranlib and self compiler compiler_type unix try result subprocess run self compiler compiler version stdout subprocess pipe stderr subprocess stdout universal_newlines true except exception pass else version result stdout lower if gcc in version ranlib shutil which gcc ranlib elif clang in version if sys platform darwin ranlib true else ranlib shutil which llvm ranlib if ranlib and has_flag self compiler flto for ext in self extensions ext extra_compile_args append flto cppflags append flto ldflags append flto if isinstance ranlib str env ranlib ranlib env cppflags join cppflags env cxxflags join cxxflags env ldflags join ldflags return env \n",
      "def build_extensions self if self compiler compiler_type msvc and os environ get mpl_disable_fh for ext in self extensions ext extra_compile_args append d fh env self add_optimization_flags for package in good_packages package do_custom_build env return super build_extensions \n",
      "def build_extension self ext orig_build_temp self build_temp self build_temp os path join self build_temp ext name try super build_extension ext finally self build_temp orig_build_temp \n",
      "def run self super run if not getattr self editable_mode false update_matplotlibrc path self build_lib matplotlib mpl data matplotlibrc \n",
      "def make_release_tree self base_dir files super make_release_tree base_dir files update_matplotlibrc path base_dir lib matplotlib mpl data matplotlibrc \n",
      "def prepare_flags name enable_lto if name in os environ if fno lto in os environ name if enable_lto is true raise valueerror configuration enable_lto true but contains fno lto format name enable_lto false return os environ name enable_lto return enable_lto \n"
     ]
    }
   ],
   "source": [
    "py = open('example.py', 'r')\n",
    "code = py.read()\n",
    "py.close()\n",
    "\n",
    "ast_tree = ast.parse(code)\n",
    "\n",
    "for node in ast.walk(ast_tree):\n",
    "    if isinstance(node, ast.FunctionDef):\n",
    "        print(clean_snippet(ast.unparse(node), line_breaks=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of popular Python packages:\n",
    "- matplotlib\n",
    "- sklearn\n",
    "- numpy\n",
    "- pandas\n",
    "- django\n",
    "- scipy\n",
    "- flask\n",
    "- requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"\"\"\n",
    "repo_urls = ['https://github.com/matplotlib/matplotlib.git',\n",
    "             'https://github.com/scikit-learn/scikit-learn.git',\n",
    "             'https://github.com/numpy/numpy.git',\n",
    "             'https://github.com/pandas-dev/pandas.git',\n",
    "             'https://github.com/django/django.git',\n",
    "             'https://github.com/scipy/scipy.git',\n",
    "             'https://github.com/pallets/flask.git',\n",
    "             'https://github.com/psf/requests.git']\n",
    "#\"\"\"\n",
    "\n",
    "#repo_urls = ['https://github.com/numpy/numpy.git']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a subclass of GitPython's RemoteProgress to track progress when fetching sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressBar(git.RemoteProgress):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # create tqdm object\n",
    "        self.bar = tqdm.tqdm()\n",
    "\n",
    "        # record start time\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "        # create status_printer function\n",
    "        self.printer = self.bar.status_printer(sys.stdout)\n",
    "\n",
    "    # update gets called when git fetch progress changes\n",
    "    def update(self, op_code, cur_count, max_count=None, message=\"\"):\n",
    "\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        \n",
    "        progress = self.bar.format_meter(n=cur_count, total=max_count, elapsed=elapsed_time)\n",
    "        \n",
    "        self.printer(progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to read a python file and\n",
    "1. count the occurences of identifier names using ASTs\n",
    "2. generate a text file to train Word2Vec on\n",
    "\n",
    "The function removes/ignores line and block comments so that the output more closely represents the logical structure of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_py(py, out_file, ast_dict, ast_total, line_breaks=True):\n",
    "    '''\n",
    "    takes two filestreams\n",
    "    '''\n",
    "\n",
    "    token_re = re.compile(r'[a-z_]+')\n",
    "    line_comment_re = re.compile(r'[ \\t]*#.*')\n",
    "    block_comment_re = re.compile(r'(\\'\\'\\')|(\\\"\\\"\\\")')\n",
    "\n",
    "    code = py.read()\n",
    "    try:\n",
    "        ast_tree = ast.parse(code)\n",
    "\n",
    "        for node in ast.walk(ast_tree):\n",
    "            \n",
    "            if isinstance(node, ast.Name):\n",
    "                ast_total += 1\n",
    "                node_id = node.id.lower()\n",
    "                if node_id in ast_dict:\n",
    "                    ast_dict[node_id] += 1\n",
    "                else:\n",
    "                    ast_dict[node_id] = 1\n",
    "            \n",
    "            elif isinstance(node, ast.FunctionDef):\n",
    "                out_file.write(clean_snippet(ast.unparse(node), line_breaks) + '\\n')\n",
    "\n",
    "    except SyntaxError:\n",
    "        pass\n",
    "    \n",
    "    return ast_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over the list of repositories. For each one, create an empty local git repository, clone the remote repository into the local one, then scrape all the python files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching https://github.com/matplotlib/matplotlib.git...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211860.0/211860.0 [00:43<00:00, 4834.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:44, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching https://github.com/scikit-learn/scikit-learn.git...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174071.0/174071.0 [01:46<00:00, 1629.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [01:47, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching https://github.com/numpy/numpy.git...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187608.0/187608.0 [01:30<00:00, 2078.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [01:31, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching https://github.com/pandas-dev/pandas.git...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 290126.0/290126.0 [04:05<00:00, 1183.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [04:06, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching https://github.com/django/django.git...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352058.0/352058.0 [01:30<00:00, 3908.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [01:31, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching https://github.com/scipy/scipy.git...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165584.0/165584.0 [00:34<00:00, 4793.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:35, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching https://github.com/pallets/flask.git...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15716.0/15716.0 [00:01<00:00, 9718.59it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching https://github.com/psf/requests.git...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16558.0/16558.0 [00:01<00:00, 9373.60it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "training = open('python_line_breaks.txt', 'w')\n",
    "training_no_line_breaks = open('python_no_breaks.txt', 'w')\n",
    "identifiers = {}\n",
    "id_total = 0\n",
    "\n",
    "# loop over repository urls\n",
    "for i in range(len(repo_urls)):\n",
    "\n",
    "    # create empty repository to clone into\n",
    "    temp_repo = git.Repo.init(os.path.join(os.getcwd(), 'temp'))\n",
    "\n",
    "    # add repo url as remote origin\n",
    "    origin = temp_repo.create_remote('origin', repo_urls[i])\n",
    "\n",
    "    # fetch remote objects\n",
    "    print('Fetching ' + repo_urls[i] + '...')\n",
    "    origin.fetch(progress=ProgressBar())\n",
    "    \n",
    "    # set up local branch to track remote\n",
    "    temp_repo.create_head('main', origin.refs.main)\n",
    "    temp_repo.heads.main.set_tracking_branch(origin.refs.main)\n",
    "    \n",
    "    # checkout local branch and pull\n",
    "    temp_repo.heads.main.checkout()\n",
    "    origin.pull()\n",
    "\n",
    "    # loop over subdirectories repo directory\n",
    "    for root, dirs, files in os.walk('temp'):\n",
    "        \n",
    "        # loop over files in subdirectory\n",
    "        for file in files:\n",
    "\n",
    "            name_ext = file.split('.')\n",
    "\n",
    "            # ignore files with no extension\n",
    "            if len(name_ext)==1:\n",
    "                pass\n",
    "            \n",
    "            # check for '.py' files\n",
    "            elif name_ext[1] == 'py':\n",
    "\n",
    "                py = open(os.path.join(root, file), 'r')\n",
    "\n",
    "                id_total = scrape_py(py, training, identifiers, id_total, line_breaks=True)\n",
    "                py.seek(0)\n",
    "                scrape_py(py, training_no_line_breaks, identifiers, id_total, line_breaks=False)\n",
    "\n",
    "                py.close()\n",
    "\n",
    "    # delete repository\n",
    "    shutil.rmtree('temp')\n",
    "\n",
    "training.close()\n",
    "training_no_line_breaks.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the identifier name data as a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.asarray(list(identifiers.items()))\n",
    "count = np.array(arr[:,1], dtype=int).reshape((arr.shape[0], 1))\n",
    "rate = count/id_total\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['identifier'] = arr[:,0]\n",
    "df['total'] = count\n",
    "df['rate'] = rate\n",
    "\n",
    "df.sort_values('total', ascending=False, inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df.drop('index', axis=1, inplace=True)\n",
    "df.to_csv('identifier_frequency.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
